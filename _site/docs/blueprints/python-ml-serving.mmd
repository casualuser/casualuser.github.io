%% Autogenerated from codemap python-ml-serving; do not edit by hand.
graph TD
  subgraph serving ["serving"]
  api["Inference API (FastAPI) (service)"]
  end
  subgraph batch ["batch"]
  worker["Batch Processor (worker)"]
  input_queue["Job Queue (queue)"]
  end
  subgraph management ["management"]
  registry["MLFlow / Registry (registry)"]
  model_store["Model Artifacts (S3) (storage)"]
  end
  api --|Prediction Endpoint|--> model_store
  api --|Prediction Endpoint|--> registry
  worker --> model_store
  worker --> input_queue
